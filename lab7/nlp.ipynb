{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b76e602f9222128",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-16T09:34:47.041946Z",
     "start_time": "2023-11-16T09:34:46.967739Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import data: Movie reviews"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "175c674269483f63"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text label\n0  There is no relation at all between Fortier an...   pos\n1  This movie is a great. The plot is very true t...   pos\n2  George P. Cosmatos' \"Rambo: First Blood Part I...   neg\n3  In the process of trying to establish the audi...   pos\n4  Yeh, I know -- you're quivering with excitemen...   neg",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>There is no relation at all between Fortier an...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This movie is a great. The plot is very true t...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>George P. Cosmatos' \"Rambo: First Blood Part I...</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>In the process of trying to establish the audi...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Yeh, I know -- you're quivering with excitemen...</td>\n      <td>neg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Download the IMDb dataset\n",
    "imdb_dataset = load_dataset('imdb')\n",
    "\n",
    "# Select 1,000 examples from each split (train and test)\n",
    "data = pd.DataFrame(imdb_dataset['train'].shuffle(seed=42).select(range(20000)))\n",
    "\n",
    "# replace target value\n",
    "data['label'] = data['label'].apply(lambda x: 'pos' if x else 'neg')\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T09:34:52.668218Z",
     "start_time": "2023-11-16T09:34:46.992678Z"
    }
   },
   "id": "9a5a728c063f9569"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing: Clean the text data \n",
    "\n",
    "Preprocessing is a crucial step in NLP that involves cleaning and transforming raw text data into a format that is suitable for machine learning algorithms and other NLP tasks. It includes several essential steps:\n",
    "\n",
    "1. **Tokenization**: Breaking down text into smaller units, such as words or subwords (tokens). Tokenization helps in understanding the structure of the text and is a fundamental step for many NLP tasks.\n",
    "\n",
    "2. **Lowercasing**: Converting all text to lowercase to ensure uniformity and to avoid treating words with different cases as different entities.\n",
    "\n",
    "3. **Removing Stopwords**: Eliminating common words (such as \"the\", \"is\", \"and\") that do not carry significant meaning and are unlikely to contribute to the analysis.\n",
    "\n",
    "4. **Removing Punctuation**: Stripping text of punctuation marks, as they often don't provide valuable information for many NLP tasks.\n",
    "\n",
    "5. **Normalization**: Standardizing text by applying techniques like lemmatization or stemming to reduce words to their base or root forms. This helps in treating different forms of words as the same token.\n",
    "\n",
    "Preprocessing in NLP significantly impacts the quality and performance of downstream tasks. Effective preprocessing ensures that the data is clean, standardized, and ready for analysis or model training, ultimately enhancing the accuracy and reliability of NLP applications.\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:33:30.337646Z",
     "start_time": "2023-11-15T16:33:29.952699Z"
    }
   },
   "id": "c3159d682b2038a2"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/azagar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/azagar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/azagar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download necessary resources (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize Lemmatizer and Stemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T09:34:52.668987Z",
     "start_time": "2023-11-16T09:34:52.659482Z"
    }
   },
   "id": "135675941b875faa"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text.lower())  # Convert text to lowercase\n",
    "\n",
    "    # Remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    words = [word.translate(table) for word in words if word.isalpha()]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Stemming (uncomment if you want to use stemming)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Join the words back into a string\n",
    "    preprocessed_text = ' '.join(lemmatized_words)\n",
    "    return preprocessed_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T09:34:52.702663Z",
     "start_time": "2023-11-16T09:34:52.668595Z"
    }
   },
   "id": "3d882c2cab326d46"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "data['clean_text'] = data['text'].apply(preprocess_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T09:36:33.652081Z",
     "start_time": "2023-11-16T09:34:52.677425Z"
    }
   },
   "id": "31ee3b41714eed72"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "'relation fortier profiler fact police series violent crime profiler look crispy fortier look classic profiler plot quite simple fortier plot far complicated fortier look like prime suspect spot similarity main character weak weirdo clairvoyance people like compare judge evaluate enjoying funny thing people writing fortier look american hand arguing prefer american series maybe language spirit think series english american way actor really good funny acting superficial'"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check preprocessed first instance\n",
    "data['clean_text'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T09:36:33.660283Z",
     "start_time": "2023-11-16T09:36:33.654916Z"
    }
   },
   "id": "c449796b3954a837"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['clean_text', 'text']], data['label'], test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T09:36:33.806122Z",
     "start_time": "2023-11-16T09:36:33.667887Z"
    }
   },
   "id": "9d3d3fd1c84778c4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature extraction 1: Convert text data to numerical features (TF-IDF or word embeddings)\n",
    "\n",
    "TF-IDF stands for Term Frequency-Inverse Document Frequency, a numerical statistic used in natural language processing (NLP) to evaluate the importance of a word in a document within a corpus.\n",
    "\n",
    "Here's a breakdown of how TF-IDF works:\n",
    "\n",
    "1. **Term Frequency (TF):** It measures how often a term (word) appears in a document. It's calculated by dividing the number of times a term appears in a document by the total number of terms in that document. The idea is that the more frequent a term is in a document, the more important it might be.\n",
    "\n",
    "   $ \\[ \\text{TF}(t, d) = \\frac{\\text{Number of times term } t \\text{ appears in document } d}{\\text{Total number of terms in document } d} \\] $\n",
    "\n",
    "2. **Inverse Document Frequency (IDF):** This part of the formula measures the significance of a term across a collection of documents (corpus). It penalizes the words that appear too frequently across documents and gives more weight to terms that are rare in the corpus. It's calculated as the logarithm of the ratio between the total number of documents and the number of documents containing the term, then adding 1 to avoid division by zero.\n",
    "\n",
    "   $ \\[ \\text{IDF}(t, D) = \\log{\\left(\\frac{\\text{Total number of documents in corpus } D}{\\text{Number of documents containing term } t}\\right)} + 1 \\] $\n",
    "\n",
    "3. **TF-IDF:** This is the product of TF and IDF. It gives a high weight to terms that are frequent in a specific document but relatively rare in the entire corpus. Terms that occur frequently across all documents get lower weights.\n",
    "\n",
    "   $ \\[ \\text{TF-IDF}(t, d, D) = \\text{TF}(t, d) \\times \\text{IDF}(t, D) \\] $\n",
    "\n",
    "Using TF-IDF, you can represent each document as a numerical vector where each dimension represents a term and its importance in that document. This technique is widely used in information retrieval, text mining, and search engine optimization, helping to determine the relevance of a document to a query or to analyze the significance of terms within documents."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T09:35:16.543838Z",
     "start_time": "2023-11-15T09:35:16.528368Z"
    }
   },
   "id": "9b42a1fa6cce658e"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "# Model building: Choose and train a classifier\n",
    "vectorizer = TfidfVectorizer()  # Use TF-IDF vectorizer for text to numerical feature conversion\n",
    "X_train_vec = vectorizer.fit_transform(X_train['clean_text'])\n",
    "X_test_vec = vectorizer.transform(X_test['clean_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T13:08:12.592441Z",
     "start_time": "2023-11-16T13:08:10.627545Z"
    }
   },
   "id": "43cd8439fd644242"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.88625\n",
      "Random Forest Accuracy: 0.84825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Logistic Regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train_vec, y_train)\n",
    "logistic_predictions = logistic_model.predict(X_test_vec)\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "print(\"Logistic Regression Accuracy:\", logistic_accuracy)\n",
    "\n",
    "# Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train_vec, y_train)\n",
    "rf_predictions = rf_model.predict(X_test_vec)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T13:08:34.902466Z",
     "start_time": "2023-11-16T13:08:13.223237Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature extraction 2: Convert text data to numerical features (Word embeddings)\n",
    "\n",
    "Word2Vec is a popular technique in natural language processing (NLP) used to represent words as numerical vectors in a continuous vector space. It's based on the idea that words with similar meanings often appear together in similar contexts and therefore should have vector representations that are close to each other in this space.\n",
    "\n",
    "There are two main architectures for Word2Vec:\n",
    "\n",
    "1. **Continuous Bag-of-Words (CBOW):** This model predicts the probability of a word given its context. It takes a context of surrounding words and tries to predict the target word. For instance, given the context words \"the cat sat on the,\" it predicts the target word \"mat.\"\n",
    "\n",
    "2. **Skip-gram:** This model works the other way around; it predicts the context words given a target word. So, given the target word \"cat,\" it tries to predict the context words \"the,\" \"sat,\" \"on,\" etc.\n",
    "\n",
    "Both models use a shallow neural network with a single hidden layer to learn the weights that represent the words as vectors. The hidden layer's weights become the word embeddings, which are the vector representations of the words.\n",
    "\n",
    "Training Word2Vec involves presenting pairs of words (input and output) to the network, adjusting the weights using techniques like backpropagation, and optimizing the network to minimize the prediction error. The resulting word vectors capture semantic relationships between words.\n",
    "\n",
    "The key benefit of Word2Vec is that it produces dense, low-dimensional representations for words, capturing semantic meaning and relationships between words. These embeddings can be used in various NLP tasks like sentiment analysis, machine translation, and information retrieval.\n",
    "\n",
    "Word2Vec's ability to represent words as continuous vectors has significantly contributed to the development of more effective NLP models and applications.\n",
    "\n",
    "![image info](w2v.png)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:16:55.397345Z",
     "start_time": "2023-11-15T16:16:53.701665Z"
    }
   },
   "id": "d84b19a6bf6812e5"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Tokenized text \n",
    "tokenized_train_text = [text.split() for text in X_train['clean_text']]\n",
    "tokenized_test_text = [text.split() for text in X_test['clean_text']]\n",
    "\n",
    "# Train Word2Vec model\n",
    "w2v_model = Word2Vec(tokenized_train_text, vector_size=100, window=5, min_count=1, workers=4, epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T09:37:06.410472Z",
     "start_time": "2023-11-16T09:36:57.766561Z"
    }
   },
   "id": "9828965dfd3a0446"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: br\n",
      "Vector: [ 1.21909343e-01  5.92590533e-02  1.05182815e+00  1.29842138e+00\n",
      "  9.34469849e-02 -1.47313035e+00  1.22275090e+00  1.03286338e+00\n",
      " -1.27847719e+00  1.06472168e-02 -3.60007375e-01 -2.31586918e-01\n",
      " -9.25996006e-01  5.66162705e-01 -5.55866957e-01 -2.34780979e+00\n",
      "  1.94273129e-01  3.67202789e-01 -1.62185669e+00 -5.09611130e-01\n",
      " -1.36729562e+00 -8.81744847e-02  1.29608643e+00  1.76797962e+00\n",
      "  1.77838728e-01  3.60358059e-02  5.04395068e-01  2.03236029e-01\n",
      " -8.18773031e-01 -5.46439052e-01 -7.96662629e-01  1.32134646e-01\n",
      " -5.75748324e-01 -1.00471580e+00 -9.18747663e-01 -2.15081394e-01\n",
      "  8.93931568e-01 -1.41501272e+00 -9.02254105e-01 -2.08485484e+00\n",
      " -5.78641653e-01  1.46873367e+00 -9.34582591e-01 -1.15586734e+00\n",
      " -7.60571361e-01 -2.05677152e-01 -1.19755685e+00 -1.85966734e-02\n",
      "  3.01922321e-01  1.05158448e+00  1.06699383e+00  6.40259385e-01\n",
      "  6.67065382e-01 -1.49239637e-02  8.37262213e-01 -1.18750989e+00\n",
      " -4.47285026e-01  1.05528045e+00 -4.04927969e-01 -1.22597562e-02\n",
      " -4.06379774e-02 -1.34167480e+00 -2.02564073e+00  1.76407710e-01\n",
      "  2.78130025e-01 -1.73265800e-01  6.81662321e-01 -4.93762523e-01\n",
      " -3.35810572e-01 -7.33095765e-01  1.14747024e+00  1.00893088e-01\n",
      " -1.85396957e+00  8.51974666e-01 -5.87338746e-01  1.22074592e+00\n",
      "  1.05424452e+00  1.81728080e-01 -6.75342008e-02 -2.50183731e-01\n",
      "  8.61910135e-02  2.25645781e+00 -3.94284964e-01  1.65479887e+00\n",
      " -7.01574922e-01  1.62977171e+00 -7.92962968e-01  1.28080797e+00\n",
      " -2.21840453e+00 -1.59294792e-02  1.30711170e-02 -4.80522402e-02\n",
      " -2.27175304e-03  7.41649449e-01 -1.18152484e-01  4.10380781e-01\n",
      " -1.17834783e+00 -7.03213692e-01 -9.97955620e-01  1.35312647e-01]\n",
      "\n",
      "\n",
      "Word: movie\n",
      "Vector: [-1.3160901  -0.57049745  0.55433714  2.006439    0.0077811  -1.2701359\n",
      "  0.3768688   1.1357147  -1.0470767  -0.30559272  0.04457191 -0.65300775\n",
      "  0.5200667   1.2189797   0.16451779 -0.62846243  1.7095454   0.96469784\n",
      " -1.8962928  -1.1449599   1.736594    0.3544182   2.3644032   0.13704713\n",
      "  1.0421575  -0.7329191  -0.05748203  0.30249166 -1.940995    0.10240132\n",
      "  1.6459184  -1.861802    0.1481619  -2.9294627  -1.4213562  -1.90379\n",
      " -0.09842137 -1.1493709   0.60482216  0.6623179  -0.10775177  1.6580861\n",
      " -0.20496003 -1.9576502   0.5147191   0.8070688   1.3759949   0.00348302\n",
      " -0.19429487  0.5669119   0.01721034  0.6362264  -0.53019667  0.24165928\n",
      "  0.92132354 -1.8508747   0.4606032  -0.2165468  -1.0838486   0.26394203\n",
      " -1.1695544  -1.4770015   0.55928385 -2.3816323  -1.5630187  -0.00839449\n",
      "  0.43602937  1.5012884   1.2933977   0.8719641   1.0696732  -0.41858917\n",
      " -1.831711   -0.3534246   0.83201414 -0.5041624   1.5900724   1.3633091\n",
      " -0.23565333 -0.4593344  -1.54844     0.01991197  1.2973514   0.6093235\n",
      " -0.91949385  0.5627548  -1.2653828  -1.2324431  -1.3198642   0.32974735\n",
      " -0.16060482 -0.63056314  0.91542494 -1.0506759   0.96419877  0.01585754\n",
      " -2.0508003  -0.174319   -0.47761476 -0.02442089]\n",
      "\n",
      "\n",
      "Word: film\n",
      "Vector: [-0.38659728 -0.83333474  0.44117424  2.6496272  -0.5486269  -2.3754833\n",
      " -0.6100977   1.2663765  -1.5897565   0.46518078 -0.5829594  -0.71770495\n",
      "  0.4727714   1.3944668  -0.02574864 -0.9787144   1.9025375   2.036827\n",
      " -1.6407479  -0.7549767   1.8589245  -0.44152203  0.9082724  -0.3493041\n",
      "  1.8259001  -0.97869366  0.6510176   0.23074557 -1.7933226  -0.8203929\n",
      "  0.93668634 -2.0646603   0.24265803 -1.0130792  -2.7736924  -0.94002336\n",
      " -0.03132681 -0.7988049   0.3296925   0.11903995 -0.35244986  2.0246913\n",
      " -1.0958414  -2.3476706   0.66612864  1.243752    0.4892793   0.03820338\n",
      "  0.65763205  0.70724034  0.23987973  0.6051119  -0.6643471  -0.22987673\n",
      "  0.8839162  -0.21621838  1.8016925  -1.5308092  -0.75411683  0.9135719\n",
      " -0.11623315 -0.7105935   0.48998812 -2.1124935  -0.48143163  0.0601057\n",
      "  0.0205519   1.6799909   1.3676462   0.06954665  0.7476958   0.71955496\n",
      " -0.67879486  0.76189584  0.6861445   0.9325644   2.066048    1.1356848\n",
      "  0.01789515 -1.3286239  -2.0480614  -0.05801702  0.6928852   1.4390199\n",
      " -0.9511331   0.10307916 -0.2806011  -1.1566952  -0.6651735  -0.1416237\n",
      " -0.83906907 -0.18480062  0.47636828 -1.0623188   0.26904678  0.82255\n",
      " -0.8558281  -0.0279453   0.28887382 -0.45287067]\n",
      "\n",
      "\n",
      "Word: one\n",
      "Vector: [-1.1584562  -0.26387167 -1.234801    0.91402     1.0947708  -0.8711222\n",
      " -0.80051935  1.2628317  -0.8895519  -1.2089369  -0.10128574  0.2257675\n",
      " -0.33476907  0.5950162  -0.7412055  -1.2767879   1.6604956  -1.4027737\n",
      " -2.0611033  -1.1203276   0.9495353  -0.4115791   2.1280808   1.8193448\n",
      " -0.9560466   0.26884985  0.6753432   0.10815179 -0.6540497  -0.45603794\n",
      "  0.37845227 -1.322063   -1.0183957  -0.7769888  -0.38699907  0.08676318\n",
      "  0.84745824 -2.124025   -2.26929     0.6080909   0.521182    1.5576677\n",
      "  0.60316616 -0.6228288  -0.06881739 -0.1111196   0.93553966  0.22178756\n",
      "  0.45991853  1.2882324   0.6079298   1.5099002  -0.16079696 -0.05557727\n",
      "  1.7310648  -0.01084712 -0.42624834  0.7767928   1.2129432   0.9041914\n",
      " -0.9837136   0.7698431   1.2925948  -1.9124041  -0.6133684  -0.9437863\n",
      " -0.75897723  1.4348774   0.70155317 -0.17528959  0.60679805 -1.607351\n",
      "  0.54246074  0.12638624  0.31964058 -0.33470154 -0.09369848  1.5963801\n",
      " -0.7551495   0.23854502 -2.1322756   0.30808225 -1.414802    0.35115072\n",
      " -1.1234212   1.2069532   0.20915918 -0.23630816 -0.42478326 -0.31281224\n",
      " -1.9649012  -0.49380502 -0.5946787   0.36555928  0.09544571 -0.03348309\n",
      " -0.67524004 -0.12570442 -0.7563585  -0.45221487]\n",
      "\n",
      "\n",
      "Word: like\n",
      "Vector: [-0.8197      0.8938665  -1.4264771   0.27095225  1.2106165  -0.37237495\n",
      " -0.34887823  0.17895703  0.32806593  0.65278745 -0.14705247  0.8535004\n",
      " -2.5817237   1.6958573  -1.7622247  -0.8862463   0.5863231  -0.12897682\n",
      "  0.16502254 -1.1861368   0.66081554 -0.7667569   0.23020533  2.3945842\n",
      " -0.75025487 -0.49262255  0.6517644   0.6306135  -1.7724372   0.06798588\n",
      "  1.2204331   1.848353    0.22121826 -1.5636296   1.0656542  -2.275167\n",
      " -1.1299466  -0.62314975 -1.8842633  -1.0263149  -0.57692367 -1.3997389\n",
      " -0.9075788   0.9674788  -1.2038157  -0.01471541  0.7341262   0.25142613\n",
      " -0.7922739  -0.0697896   1.1523639   1.4638829   1.6689237  -0.7964706\n",
      "  0.45750248 -2.4032128  -0.13341907 -1.6244524   0.18403316 -0.76767236\n",
      " -0.15464613 -2.2157936  -1.5126858   0.358787   -1.7985564   0.07728608\n",
      "  2.3906872   0.84410787 -1.8961976   2.8869724   0.8853043   1.4013554\n",
      " -1.6174556  -0.18941624  1.036615   -0.03094619 -0.5969339   2.3852358\n",
      " -0.00395417 -0.21831359 -1.4492337  -1.8047355  -0.35793728 -0.647298\n",
      " -1.8941963  -0.5431709   1.3459389   0.25548676 -2.3527524   0.73042923\n",
      " -0.09614471 -1.078131    1.3255738  -0.02828738  0.942288   -2.0624418\n",
      "  0.636105    1.9622203   0.17234975  0.11412331]\n"
     ]
    }
   ],
   "source": [
    "# Get all words and their vectors in the Word2Vec model's vocabulary\n",
    "all_words = w2v_model.wv.index_to_key\n",
    "word_vectors = {word: w2v_model.wv[word] for word in all_words[:5]}\n",
    "\n",
    "# Print the word vectors\n",
    "for word, vector in word_vectors.items():\n",
    "    print(f\"Word: {word}\")\n",
    "    print(f\"Vector: {vector}\")\n",
    "    print(\"\\n\")  # Add a newline for better readability"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T09:37:06.423932Z",
     "start_time": "2023-11-16T09:37:06.409648Z"
    }
   },
   "id": "725eba6b29d0d617"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar word: explosion, Similarity: 0.6980080604553223\n",
      "Similar word: crash, Similarity: 0.6879973411560059\n",
      "Similar word: chase, Similarity: 0.6702556014060974\n",
      "Similar word: driving, Similarity: 0.6673227548599243\n",
      "Similar word: fire, Similarity: 0.6669660806655884\n",
      "Similar word: bike, Similarity: 0.6648144721984863\n",
      "Similar word: plane, Similarity: 0.6571458578109741\n",
      "Similar word: helicopter, Similarity: 0.641711950302124\n",
      "Similar word: truck, Similarity: 0.6379563808441162\n",
      "Similar word: wheel, Similarity: 0.6322101950645447\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'w2v_model' is your trained Word2Vec model\n",
    "\n",
    "# Find similar words to a specific word\n",
    "similar_words = w2v_model.wv.most_similar('car', topn=10)\n",
    "\n",
    "# 'word' is the word for which you want to find similar words, and 'topn' specifies the number of similar words to retrieve\n",
    "\n",
    "# Print the similar words and their similarity scores\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"Similar word: {word}, Similarity: {similarity}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T17:06:08.276810Z",
     "start_time": "2023-11-15T17:04:40.472606Z"
    }
   },
   "id": "bb26811258d5611c"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azagar/miniconda3/envs/is/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n",
      "\n",
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "customdata": [
          [
           "br"
          ],
          [
           "movie"
          ],
          [
           "film"
          ],
          [
           "one"
          ],
          [
           "like"
          ],
          [
           "time"
          ],
          [
           "good"
          ],
          [
           "character"
          ],
          [
           "would"
          ],
          [
           "story"
          ],
          [
           "even"
          ],
          [
           "get"
          ],
          [
           "see"
          ],
          [
           "make"
          ],
          [
           "really"
          ],
          [
           "scene"
          ],
          [
           "well"
          ],
          [
           "much"
          ],
          [
           "could"
          ],
          [
           "people"
          ],
          [
           "also"
          ],
          [
           "bad"
          ],
          [
           "first"
          ],
          [
           "great"
          ],
          [
           "way"
          ],
          [
           "show"
          ],
          [
           "thing"
          ],
          [
           "made"
          ],
          [
           "think"
          ],
          [
           "life"
          ],
          [
           "go"
          ],
          [
           "know"
          ],
          [
           "watch"
          ],
          [
           "love"
          ],
          [
           "many"
          ],
          [
           "two"
          ],
          [
           "plot"
          ],
          [
           "actor"
          ],
          [
           "look"
          ],
          [
           "say"
          ],
          [
           "seen"
          ],
          [
           "never"
          ],
          [
           "little"
          ],
          [
           "end"
          ],
          [
           "acting"
          ],
          [
           "year"
          ],
          [
           "best"
          ],
          [
           "ever"
          ],
          [
           "take"
          ],
          [
           "man"
          ],
          [
           "better"
          ],
          [
           "come"
          ],
          [
           "still"
          ],
          [
           "work"
          ],
          [
           "part"
          ],
          [
           "find"
          ],
          [
           "want"
          ],
          [
           "something"
          ],
          [
           "give"
          ],
          [
           "back"
          ],
          [
           "director"
          ],
          [
           "performance"
          ],
          [
           "lot"
          ],
          [
           "woman"
          ],
          [
           "real"
          ],
          [
           "watching"
          ],
          [
           "though"
          ],
          [
           "play"
          ],
          [
           "another"
          ],
          [
           "guy"
          ],
          [
           "actually"
          ],
          [
           "new"
          ],
          [
           "nothing"
          ],
          [
           "role"
          ],
          [
           "old"
          ],
          [
           "going"
          ],
          [
           "funny"
          ],
          [
           "every"
          ],
          [
           "u"
          ],
          [
           "cast"
          ],
          [
           "girl"
          ],
          [
           "point"
          ],
          [
           "world"
          ],
          [
           "fact"
          ],
          [
           "pretty"
          ],
          [
           "seems"
          ],
          [
           "quite"
          ],
          [
           "day"
          ],
          [
           "feel"
          ],
          [
           "got"
          ],
          [
           "young"
          ],
          [
           "thought"
          ],
          [
           "around"
          ],
          [
           "minute"
          ],
          [
           "ca"
          ],
          [
           "comedy"
          ],
          [
           "enough"
          ],
          [
           "star"
          ],
          [
           "right"
          ],
          [
           "horror"
          ],
          [
           "may"
          ],
          [
           "big"
          ],
          [
           "however"
          ],
          [
           "original"
          ],
          [
           "without"
          ],
          [
           "action"
          ],
          [
           "bit"
          ],
          [
           "always"
          ],
          [
           "fan"
          ],
          [
           "family"
          ],
          [
           "line"
          ],
          [
           "friend"
          ],
          [
           "almost"
          ],
          [
           "series"
          ],
          [
           "long"
          ],
          [
           "saw"
          ],
          [
           "must"
          ],
          [
           "least"
          ],
          [
           "script"
          ],
          [
           "try"
          ],
          [
           "interesting"
          ],
          [
           "set"
          ],
          [
           "whole"
          ],
          [
           "shot"
          ],
          [
           "done"
          ],
          [
           "far"
          ],
          [
           "music"
          ],
          [
           "probably"
          ],
          [
           "last"
          ],
          [
           "kind"
          ],
          [
           "anything"
          ],
          [
           "kid"
          ],
          [
           "might"
          ],
          [
           "start"
          ],
          [
           "since"
          ],
          [
           "reason"
          ],
          [
           "rather"
          ],
          [
           "place"
          ],
          [
           "moment"
          ],
          [
           "yet"
          ],
          [
           "put"
          ],
          [
           "book"
          ],
          [
           "sure"
          ],
          [
           "effect"
          ],
          [
           "worst"
          ],
          [
           "away"
          ],
          [
           "need"
          ],
          [
           "child"
          ],
          [
           "idea"
          ],
          [
           "episode"
          ],
          [
           "anyone"
          ],
          [
           "let"
          ],
          [
           "making"
          ],
          [
           "turn"
          ],
          [
           "audience"
          ],
          [
           "tv"
          ],
          [
           "played"
          ],
          [
           "course"
          ],
          [
           "especially"
          ],
          [
           "found"
          ],
          [
           "believe"
          ],
          [
           "although"
          ],
          [
           "fun"
          ],
          [
           "tell"
          ],
          [
           "job"
          ],
          [
           "version"
          ],
          [
           "mean"
          ],
          [
           "trying"
          ],
          [
           "different"
          ],
          [
           "hard"
          ],
          [
           "maybe"
          ],
          [
           "ending"
          ],
          [
           "dvd"
          ],
          [
           "american"
          ],
          [
           "problem"
          ],
          [
           "someone"
          ],
          [
           "screen"
          ],
          [
           "everyone"
          ],
          [
           "money"
          ],
          [
           "everything"
          ],
          [
           "sense"
          ],
          [
           "looking"
          ],
          [
           "true"
          ],
          [
           "help"
          ],
          [
           "keep"
          ],
          [
           "instead"
          ],
          [
           "main"
          ],
          [
           "watched"
          ],
          [
           "worth"
          ],
          [
           "john"
          ],
          [
           "beautiful"
          ],
          [
           "said"
          ],
          [
           "three"
          ],
          [
           "second"
          ],
          [
           "night"
          ],
          [
           "house"
          ],
          [
           "later"
          ],
          [
           "together"
          ],
          [
           "left"
          ],
          [
           "seem"
          ]
         ],
         "hovertemplate": "word=%{customdata[0]}<br>cluster=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           3,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           3,
           4,
           4,
           4,
           4,
           4,
           3,
           4,
           4,
           4,
           3,
           4,
           2,
           4,
           3,
           4,
           4,
           4,
           2,
           4,
           3,
           4,
           3,
           4,
           2,
           3,
           4,
           4,
           4,
           4,
           2,
           3,
           4,
           4,
           4,
           4,
           4,
           4,
           3,
           4,
           4,
           2,
           4,
           3,
           4,
           4,
           4,
           4,
           2,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           3,
           4,
           3,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           3,
           4,
           3,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           3,
           4,
           3,
           4,
           4,
           4,
           4,
           4,
           3,
           4,
           4,
           2,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           2,
           4,
           4,
           3,
           4,
           4,
           4,
           4,
           4,
           0,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           3,
           4,
           4,
           4,
           4,
           4,
           2,
           2,
           4,
           3,
           4,
           3,
           3,
           3,
           4,
           4,
           4
          ],
          "coloraxis": "coloraxis",
          "symbol": "circle",
          "opacity": 0.7,
          "size": 8
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "x": [
          -2.970665693283081,
          -6.376161575317383,
          -5.360296726226807,
          -3.2247743606567383,
          -2.6589267253875732,
          -3.9978621006011963,
          -3.7349743843078613,
          -1.7342184782028198,
          -4.577179431915283,
          -4.154294490814209,
          -3.874549627304077,
          -2.3917291164398193,
          -3.7385828495025635,
          -4.086136341094971,
          -5.322244644165039,
          -2.405426025390625,
          -2.9528732299804688,
          -4.588986873626709,
          -4.814891338348389,
          -4.490289211273193,
          -0.8783385157585144,
          -5.048601150512695,
          -2.91701078414917,
          -2.1422712802886963,
          -3.5111751556396484,
          -3.191342830657959,
          -5.477431774139404,
          -4.112131595611572,
          -4.480140686035156,
          -0.35781627893447876,
          -1.4662030935287476,
          -3.4877896308898926,
          -5.617564678192139,
          -0.7695214152336121,
          -4.809948921203613,
          -1.278131127357483,
          -5.57064151763916,
          -2.670440435409546,
          -2.2911224365234375,
          -4.129485130310059,
          -4.4848713874816895,
          -3.2451367378234863,
          -2.838252544403076,
          -2.881617784500122,
          -4.042907238006592,
          -1.423325538635254,
          -1.3841086626052856,
          -3.9341161251068115,
          -0.909196138381958,
          2.068242073059082,
          -4.267233371734619,
          -1.717551827430725,
          -3.742985725402832,
          -1.871364712715149,
          -2.2442116737365723,
          -0.7174152731895447,
          -2.4807353019714355,
          -4.844899654388428,
          -2.385859966278076,
          -1.0458543300628662,
          -1.9376139640808105,
          0.5054988861083984,
          -4.613900184631348,
          1.8075127601623535,
          -2.383300542831421,
          -5.611941337585449,
          -3.2206530570983887,
          2.7382946014404297,
          -1.343629240989685,
          -0.28000858426094055,
          -3.981816291809082,
          -0.14982473850250244,
          -4.655275344848633,
          1.7989672422409058,
          0.1897461861371994,
          -3.215153217315674,
          -3.707608461380005,
          -3.6898162364959717,
          -2.581913709640503,
          -0.9803346395492554,
          1.655497431755066,
          -3.8141283988952637,
          -1.1690937280654907,
          -3.187343120574951,
          -2.7765402793884277,
          -1.503811001777649,
          -3.7106270790100098,
          -1.0193755626678467,
          -5.225472450256348,
          -3.0525217056274414,
          3.5411581993103027,
          -3.860246419906616,
          -0.4366530179977417,
          -5.703432559967041,
          -3.577064037322998,
          -3.7474915981292725,
          -3.8186159133911133,
          0.8515832424163818,
          -2.3821702003479004,
          -5.302815914154053,
          -2.992476224899292,
          -1.3497769832611084,
          -2.8356618881225586,
          -4.099156856536865,
          -3.1127541065216064,
          -4.853351593017578,
          -3.425128698348999,
          -1.242865800857544,
          -2.541496753692627,
          0.8955675363540649,
          -3.1074399948120117,
          1.5350468158721924,
          -3.055661678314209,
          -3.5898001194000244,
          -3.1120731830596924,
          -2.8907923698425293,
          -2.1934216022491455,
          -4.795995235443115,
          -4.7437238693237305,
          -1.108496069908142,
          -3.574955940246582,
          -1.0087621212005615,
          -4.417250156402588,
          -1.884235143661499,
          -3.694819450378418,
          -3.6636605262756348,
          -2.955657958984375,
          -3.915667772293091,
          -1.523145079612732,
          -3.1981277465820312,
          -5.069584846496582,
          -1.4654473066329956,
          -4.06524658203125,
          -1.1535216569900513,
          -2.5201425552368164,
          -3.5454537868499756,
          -2.6195967197418213,
          -1.322964072227478,
          -2.504102945327759,
          -2.230745553970337,
          -1.8262345790863037,
          -2.5837910175323486,
          -4.212520599365234,
          -4.9902143478393555,
          -3.2580225467681885,
          -1.6578922271728516,
          -2.296416997909546,
          -0.3055664598941803,
          -3.7803051471710205,
          -3.352433681488037,
          -4.544101715087891,
          -3.478289842605591,
          -3.096026659011841,
          0.6130487322807312,
          -4.549623012542725,
          -3.343895435333252,
          5.461035251617432,
          -0.6557958126068115,
          -0.7596956491470337,
          -3.2704203128814697,
          -2.8707754611968994,
          -2.5342869758605957,
          -3.7986562252044678,
          -0.7144360542297363,
          1.6813125610351562,
          -2.2111709117889404,
          -3.3642702102661133,
          -0.4956740140914917,
          -2.727701425552368,
          -3.482954263687134,
          -4.440619468688965,
          -5.347943305969238,
          -5.126344680786133,
          -0.202060267329216,
          -2.2133853435516357,
          -2.256279706954956,
          -1.517505407333374,
          -2.7787318229675293,
          -1.74761164188385,
          -3.809739112854004,
          -3.9434635639190674,
          -1.4438121318817139,
          -2.1678009033203125,
          0.8563699126243591,
          -2.086547613143921,
          -1.6369826793670654,
          -1.8826838731765747,
          -5.101881980895996,
          -3.9638514518737793,
          4.549531936645508,
          0.9058499336242676,
          -3.1499874591827393,
          -0.2059057056903839,
          -2.2044897079467773,
          -0.16278387606143951,
          1.8313159942626953,
          1.1396279335021973,
          -1.0793323516845703,
          -2.113811492919922,
          -2.9573638439178467
         ],
         "xaxis": "x",
         "y": [
          1.779975414276123,
          2.7562997341156006,
          2.429914712905884,
          2.3113434314727783,
          2.106502056121826,
          2.6860511302948,
          1.968704104423523,
          1.4010381698608398,
          2.5813040733337402,
          3.1510095596313477,
          2.3587849140167236,
          3.239488124847412,
          2.8600010871887207,
          2.8789279460906982,
          2.5390853881835938,
          2.6961700916290283,
          2.0130374431610107,
          2.2592837810516357,
          2.572315216064453,
          4.903062343597412,
          1.0860514640808105,
          3.5311696529388428,
          2.4893250465393066,
          1.376209020614624,
          2.819010019302368,
          2.518123149871826,
          3.39142107963562,
          2.09383487701416,
          2.491021156311035,
          3.383509635925293,
          3.4925830364227295,
          3.201925039291382,
          3.0335676670074463,
          2.0848917961120605,
          3.6565701961517334,
          2.6531012058258057,
          4.167646408081055,
          -0.49596938490867615,
          1.6996080875396729,
          2.446394920349121,
          2.1081864833831787,
          2.529033899307251,
          2.7793896198272705,
          3.947671413421631,
          0.758665919303894,
          1.7251538038253784,
          0.7517901659011841,
          1.996272325515747,
          3.7833800315856934,
          1.7342884540557861,
          1.8973641395568848,
          3.0721304416656494,
          2.3534607887268066,
          1.715125560760498,
          1.4980270862579346,
          3.5279183387756348,
          3.511819362640381,
          3.2158429622650146,
          1.9091295003890991,
          3.3414926528930664,
          0.2508458197116852,
          -2.290985107421875,
          2.6635797023773193,
          2.620450019836426,
          3.127922534942627,
          2.9748005867004395,
          1.817870020866394,
          -1.0249929428100586,
          2.4841701984405518,
          1.8957455158233643,
          2.5282528400421143,
          2.8043813705444336,
          2.9656615257263184,
          -2.2119014263153076,
          2.2486090660095215,
          3.5322093963623047,
          2.109178304672241,
          3.248009443283081,
          3.5863730907440186,
          -0.723450243473053,
          2.1672966480255127,
          3.2319095134735107,
          3.4702510833740234,
          2.245398759841919,
          1.7307416200637817,
          2.359222412109375,
          1.7320984601974487,
          2.064572811126709,
          3.8638112545013428,
          2.0007498264312744,
          1.2108538150787354,
          1.8830273151397705,
          3.96657133102417,
          4.037160873413086,
          2.173781633377075,
          1.5752989053726196,
          2.5075318813323975,
          -0.9317830204963684,
          2.6932637691497803,
          4.137603282928467,
          2.385977268218994,
          2.3719565868377686,
          2.1779215335845947,
          2.1266655921936035,
          3.5181126594543457,
          3.8496077060699463,
          2.1018877029418945,
          0.24123533070087433,
          0.18356706202030182,
          3.2135117053985596,
          1.7345714569091797,
          1.4603800773620605,
          2.204256057739258,
          2.571455955505371,
          2.8688228130340576,
          1.9580727815628052,
          1.5778703689575195,
          2.2802000045776367,
          1.3734675645828247,
          3.2886953353881836,
          3.376028299331665,
          3.380666732788086,
          3.989839553833008,
          3.4375011920928955,
          2.216235637664795,
          2.411639928817749,
          1.6042944192886353,
          1.7580519914627075,
          1.8020431995391846,
          2.8229527473449707,
          2.7122626304626465,
          2.552245616912842,
          2.5294744968414307,
          2.966447114944458,
          1.4594277143478394,
          2.5012028217315674,
          2.790050983428955,
          3.7395405769348145,
          2.256553888320923,
          2.220872640609741,
          2.4712655544281006,
          2.0289368629455566,
          2.4763171672821045,
          4.491590976715088,
          2.8888285160064697,
          3.9271697998046875,
          3.1030237674713135,
          2.64436936378479,
          3.1542086601257324,
          2.7032859325408936,
          2.8260085582733154,
          3.0983755588531494,
          2.45174503326416,
          1.9934371709823608,
          4.037731170654297,
          2.097036361694336,
          -1.5923751592636108,
          1.3907057046890259,
          0.4823702573776245,
          2.7992076873779297,
          2.5264861583709717,
          1.2712019681930542,
          2.5425865650177,
          2.8270535469055176,
          -0.25484731793403625,
          0.13973164558410645,
          2.7386252880096436,
          3.2224154472351074,
          4.124272346496582,
          3.0907275676727295,
          2.336672067642212,
          3.6453850269317627,
          3.4330692291259766,
          2.465137004852295,
          3.550503730773926,
          2.7809770107269287,
          0.9283844828605652,
          2.327301502227783,
          2.7945711612701416,
          3.2427444458007812,
          4.421971321105957,
          1.7736446857452393,
          2.7686779499053955,
          2.311237335205078,
          3.8349225521087646,
          2.753448724746704,
          2.850940465927124,
          2.682387351989746,
          2.4443447589874268,
          -2.221799373626709,
          1.1924567222595215,
          1.4921501874923706,
          2.21142315864563,
          2.194798469543457,
          2.121577739715576,
          3.2759296894073486,
          1.910482406616211,
          2.6444597244262695,
          3.5502912998199463,
          3.310823678970337
         ],
         "yaxis": "y",
         "type": "scatter"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "type": "scattergl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "bgcolor": "#E5ECF6",
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "#E5ECF6",
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "white",
           "landcolor": "#E5ECF6",
           "subunitcolor": "white",
           "showland": true,
           "showlakes": true,
           "lakecolor": "white"
          },
          "title": {
           "x": 0.05
          },
          "mapbox": {
           "style": "light"
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0.0,
          1.0
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.0,
          1.0
         ],
         "title": {
          "text": ""
         }
        },
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "cluster"
          }
         },
         "colorscale": [
          [
           0.0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1.0,
           "#f0f921"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "title": {
         "text": "Word2Vec Clusters (Subset of Words)"
        },
        "height": 600,
        "width": 800,
        "showlegend": true
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"6e0514ba-741f-4bf0-b2de-5888314b3480\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6e0514ba-741f-4bf0-b2de-5888314b3480\")) {                    Plotly.newPlot(                        \"6e0514ba-741f-4bf0-b2de-5888314b3480\",                        [{\"customdata\":[[\"br\"],[\"movie\"],[\"film\"],[\"one\"],[\"like\"],[\"time\"],[\"good\"],[\"character\"],[\"would\"],[\"story\"],[\"even\"],[\"get\"],[\"see\"],[\"make\"],[\"really\"],[\"scene\"],[\"well\"],[\"much\"],[\"could\"],[\"people\"],[\"also\"],[\"bad\"],[\"first\"],[\"great\"],[\"way\"],[\"show\"],[\"thing\"],[\"made\"],[\"think\"],[\"life\"],[\"go\"],[\"know\"],[\"watch\"],[\"love\"],[\"many\"],[\"two\"],[\"plot\"],[\"actor\"],[\"look\"],[\"say\"],[\"seen\"],[\"never\"],[\"little\"],[\"end\"],[\"acting\"],[\"year\"],[\"best\"],[\"ever\"],[\"take\"],[\"man\"],[\"better\"],[\"come\"],[\"still\"],[\"work\"],[\"part\"],[\"find\"],[\"want\"],[\"something\"],[\"give\"],[\"back\"],[\"director\"],[\"performance\"],[\"lot\"],[\"woman\"],[\"real\"],[\"watching\"],[\"though\"],[\"play\"],[\"another\"],[\"guy\"],[\"actually\"],[\"new\"],[\"nothing\"],[\"role\"],[\"old\"],[\"going\"],[\"funny\"],[\"every\"],[\"u\"],[\"cast\"],[\"girl\"],[\"point\"],[\"world\"],[\"fact\"],[\"pretty\"],[\"seems\"],[\"quite\"],[\"day\"],[\"feel\"],[\"got\"],[\"young\"],[\"thought\"],[\"around\"],[\"minute\"],[\"ca\"],[\"comedy\"],[\"enough\"],[\"star\"],[\"right\"],[\"horror\"],[\"may\"],[\"big\"],[\"however\"],[\"original\"],[\"without\"],[\"action\"],[\"bit\"],[\"always\"],[\"fan\"],[\"family\"],[\"line\"],[\"friend\"],[\"almost\"],[\"series\"],[\"long\"],[\"saw\"],[\"must\"],[\"least\"],[\"script\"],[\"try\"],[\"interesting\"],[\"set\"],[\"whole\"],[\"shot\"],[\"done\"],[\"far\"],[\"music\"],[\"probably\"],[\"last\"],[\"kind\"],[\"anything\"],[\"kid\"],[\"might\"],[\"start\"],[\"since\"],[\"reason\"],[\"rather\"],[\"place\"],[\"moment\"],[\"yet\"],[\"put\"],[\"book\"],[\"sure\"],[\"effect\"],[\"worst\"],[\"away\"],[\"need\"],[\"child\"],[\"idea\"],[\"episode\"],[\"anyone\"],[\"let\"],[\"making\"],[\"turn\"],[\"audience\"],[\"tv\"],[\"played\"],[\"course\"],[\"especially\"],[\"found\"],[\"believe\"],[\"although\"],[\"fun\"],[\"tell\"],[\"job\"],[\"version\"],[\"mean\"],[\"trying\"],[\"different\"],[\"hard\"],[\"maybe\"],[\"ending\"],[\"dvd\"],[\"american\"],[\"problem\"],[\"someone\"],[\"screen\"],[\"everyone\"],[\"money\"],[\"everything\"],[\"sense\"],[\"looking\"],[\"true\"],[\"help\"],[\"keep\"],[\"instead\"],[\"main\"],[\"watched\"],[\"worth\"],[\"john\"],[\"beautiful\"],[\"said\"],[\"three\"],[\"second\"],[\"night\"],[\"house\"],[\"later\"],[\"together\"],[\"left\"],[\"seem\"]],\"hovertemplate\":\"word=%{customdata[0]}\\u003cbr\\u003ecluster=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,3,4,4,4,4,4,3,4,4,4,3,4,2,4,3,4,4,4,2,4,3,4,3,4,2,3,4,4,4,4,2,3,4,4,4,4,4,4,3,4,4,2,4,3,4,4,4,4,2,4,4,4,4,4,4,4,4,4,4,4,3,4,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,3,4,3,4,4,4,4,4,4,4,4,4,4,4,3,4,3,4,4,4,4,4,3,4,4,2,4,4,4,4,4,4,4,2,4,4,3,4,4,4,4,4,0,4,4,4,4,4,4,4,4,4,3,4,4,4,4,4,2,2,4,3,4,3,3,3,4,4,4],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\",\"opacity\":0.7,\"size\":8},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[-2.970665693283081,-6.376161575317383,-5.360296726226807,-3.2247743606567383,-2.6589267253875732,-3.9978621006011963,-3.7349743843078613,-1.7342184782028198,-4.577179431915283,-4.154294490814209,-3.874549627304077,-2.3917291164398193,-3.7385828495025635,-4.086136341094971,-5.322244644165039,-2.405426025390625,-2.9528732299804688,-4.588986873626709,-4.814891338348389,-4.490289211273193,-0.8783385157585144,-5.048601150512695,-2.91701078414917,-2.1422712802886963,-3.5111751556396484,-3.191342830657959,-5.477431774139404,-4.112131595611572,-4.480140686035156,-0.35781627893447876,-1.4662030935287476,-3.4877896308898926,-5.617564678192139,-0.7695214152336121,-4.809948921203613,-1.278131127357483,-5.57064151763916,-2.670440435409546,-2.2911224365234375,-4.129485130310059,-4.4848713874816895,-3.2451367378234863,-2.838252544403076,-2.881617784500122,-4.042907238006592,-1.423325538635254,-1.3841086626052856,-3.9341161251068115,-0.909196138381958,2.068242073059082,-4.267233371734619,-1.717551827430725,-3.742985725402832,-1.871364712715149,-2.2442116737365723,-0.7174152731895447,-2.4807353019714355,-4.844899654388428,-2.385859966278076,-1.0458543300628662,-1.9376139640808105,0.5054988861083984,-4.613900184631348,1.8075127601623535,-2.383300542831421,-5.611941337585449,-3.2206530570983887,2.7382946014404297,-1.343629240989685,-0.28000858426094055,-3.981816291809082,-0.14982473850250244,-4.655275344848633,1.7989672422409058,0.1897461861371994,-3.215153217315674,-3.707608461380005,-3.6898162364959717,-2.581913709640503,-0.9803346395492554,1.655497431755066,-3.8141283988952637,-1.1690937280654907,-3.187343120574951,-2.7765402793884277,-1.503811001777649,-3.7106270790100098,-1.0193755626678467,-5.225472450256348,-3.0525217056274414,3.5411581993103027,-3.860246419906616,-0.4366530179977417,-5.703432559967041,-3.577064037322998,-3.7474915981292725,-3.8186159133911133,0.8515832424163818,-2.3821702003479004,-5.302815914154053,-2.992476224899292,-1.3497769832611084,-2.8356618881225586,-4.099156856536865,-3.1127541065216064,-4.853351593017578,-3.425128698348999,-1.242865800857544,-2.541496753692627,0.8955675363540649,-3.1074399948120117,1.5350468158721924,-3.055661678314209,-3.5898001194000244,-3.1120731830596924,-2.8907923698425293,-2.1934216022491455,-4.795995235443115,-4.7437238693237305,-1.108496069908142,-3.574955940246582,-1.0087621212005615,-4.417250156402588,-1.884235143661499,-3.694819450378418,-3.6636605262756348,-2.955657958984375,-3.915667772293091,-1.523145079612732,-3.1981277465820312,-5.069584846496582,-1.4654473066329956,-4.06524658203125,-1.1535216569900513,-2.5201425552368164,-3.5454537868499756,-2.6195967197418213,-1.322964072227478,-2.504102945327759,-2.230745553970337,-1.8262345790863037,-2.5837910175323486,-4.212520599365234,-4.9902143478393555,-3.2580225467681885,-1.6578922271728516,-2.296416997909546,-0.3055664598941803,-3.7803051471710205,-3.352433681488037,-4.544101715087891,-3.478289842605591,-3.096026659011841,0.6130487322807312,-4.549623012542725,-3.343895435333252,5.461035251617432,-0.6557958126068115,-0.7596956491470337,-3.2704203128814697,-2.8707754611968994,-2.5342869758605957,-3.7986562252044678,-0.7144360542297363,1.6813125610351562,-2.2111709117889404,-3.3642702102661133,-0.4956740140914917,-2.727701425552368,-3.482954263687134,-4.440619468688965,-5.347943305969238,-5.126344680786133,-0.202060267329216,-2.2133853435516357,-2.256279706954956,-1.517505407333374,-2.7787318229675293,-1.74761164188385,-3.809739112854004,-3.9434635639190674,-1.4438121318817139,-2.1678009033203125,0.8563699126243591,-2.086547613143921,-1.6369826793670654,-1.8826838731765747,-5.101881980895996,-3.9638514518737793,4.549531936645508,0.9058499336242676,-3.1499874591827393,-0.2059057056903839,-2.2044897079467773,-0.16278387606143951,1.8313159942626953,1.1396279335021973,-1.0793323516845703,-2.113811492919922,-2.9573638439178467],\"xaxis\":\"x\",\"y\":[1.779975414276123,2.7562997341156006,2.429914712905884,2.3113434314727783,2.106502056121826,2.6860511302948,1.968704104423523,1.4010381698608398,2.5813040733337402,3.1510095596313477,2.3587849140167236,3.239488124847412,2.8600010871887207,2.8789279460906982,2.5390853881835938,2.6961700916290283,2.0130374431610107,2.2592837810516357,2.572315216064453,4.903062343597412,1.0860514640808105,3.5311696529388428,2.4893250465393066,1.376209020614624,2.819010019302368,2.518123149871826,3.39142107963562,2.09383487701416,2.491021156311035,3.383509635925293,3.4925830364227295,3.201925039291382,3.0335676670074463,2.0848917961120605,3.6565701961517334,2.6531012058258057,4.167646408081055,-0.49596938490867615,1.6996080875396729,2.446394920349121,2.1081864833831787,2.529033899307251,2.7793896198272705,3.947671413421631,0.758665919303894,1.7251538038253784,0.7517901659011841,1.996272325515747,3.7833800315856934,1.7342884540557861,1.8973641395568848,3.0721304416656494,2.3534607887268066,1.715125560760498,1.4980270862579346,3.5279183387756348,3.511819362640381,3.2158429622650146,1.9091295003890991,3.3414926528930664,0.2508458197116852,-2.290985107421875,2.6635797023773193,2.620450019836426,3.127922534942627,2.9748005867004395,1.817870020866394,-1.0249929428100586,2.4841701984405518,1.8957455158233643,2.5282528400421143,2.8043813705444336,2.9656615257263184,-2.2119014263153076,2.2486090660095215,3.5322093963623047,2.109178304672241,3.248009443283081,3.5863730907440186,-0.723450243473053,2.1672966480255127,3.2319095134735107,3.4702510833740234,2.245398759841919,1.7307416200637817,2.359222412109375,1.7320984601974487,2.064572811126709,3.8638112545013428,2.0007498264312744,1.2108538150787354,1.8830273151397705,3.96657133102417,4.037160873413086,2.173781633377075,1.5752989053726196,2.5075318813323975,-0.9317830204963684,2.6932637691497803,4.137603282928467,2.385977268218994,2.3719565868377686,2.1779215335845947,2.1266655921936035,3.5181126594543457,3.8496077060699463,2.1018877029418945,0.24123533070087433,0.18356706202030182,3.2135117053985596,1.7345714569091797,1.4603800773620605,2.204256057739258,2.571455955505371,2.8688228130340576,1.9580727815628052,1.5778703689575195,2.2802000045776367,1.3734675645828247,3.2886953353881836,3.376028299331665,3.380666732788086,3.989839553833008,3.4375011920928955,2.216235637664795,2.411639928817749,1.6042944192886353,1.7580519914627075,1.8020431995391846,2.8229527473449707,2.7122626304626465,2.552245616912842,2.5294744968414307,2.966447114944458,1.4594277143478394,2.5012028217315674,2.790050983428955,3.7395405769348145,2.256553888320923,2.220872640609741,2.4712655544281006,2.0289368629455566,2.4763171672821045,4.491590976715088,2.8888285160064697,3.9271697998046875,3.1030237674713135,2.64436936378479,3.1542086601257324,2.7032859325408936,2.8260085582733154,3.0983755588531494,2.45174503326416,1.9934371709823608,4.037731170654297,2.097036361694336,-1.5923751592636108,1.3907057046890259,0.4823702573776245,2.7992076873779297,2.5264861583709717,1.2712019681930542,2.5425865650177,2.8270535469055176,-0.25484731793403625,0.13973164558410645,2.7386252880096436,3.2224154472351074,4.124272346496582,3.0907275676727295,2.336672067642212,3.6453850269317627,3.4330692291259766,2.465137004852295,3.550503730773926,2.7809770107269287,0.9283844828605652,2.327301502227783,2.7945711612701416,3.2427444458007812,4.421971321105957,1.7736446857452393,2.7686779499053955,2.311237335205078,3.8349225521087646,2.753448724746704,2.850940465927124,2.682387351989746,2.4443447589874268,-2.221799373626709,1.1924567222595215,1.4921501874923706,2.21142315864563,2.194798469543457,2.121577739715576,3.2759296894073486,1.910482406616211,2.6444597244262695,3.5502912998199463,3.310823678970337],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"cluster\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Word2Vec Clusters (Subset of Words)\"},\"height\":600,\"width\":800,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('6e0514ba-741f-4bf0-b2de-5888314b3480');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data (Replace this part with your w2v_model and all_words)\n",
    "# Here, 'word_vectors' and 'all_words' are assumed to be pre-defined\n",
    "all_words = w2v_model.wv.index_to_key\n",
    "word_vectors = {word: w2v_model.wv[word] for word in all_words}\n",
    "\n",
    "# Print the word vectors\n",
    "words = []\n",
    "vecs = []\n",
    "for word, vector in word_vectors.items():\n",
    "    words.append(word)\n",
    "    vecs.append(vector)\n",
    "vecs = np.array(vecs)\n",
    "\n",
    "# Number of clusters\n",
    "num_clusters = 5  # Change this to the number of clusters you want\n",
    "\n",
    "# Clustering using KMeans\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "kmeans.fit(vecs)\n",
    "\n",
    "# Reduce dimensions for visualization (PCA)\n",
    "pca = PCA(n_components=2)\n",
    "word_vecs_2d = pca.fit_transform(vecs)\n",
    "\n",
    "# Choose a subset of words to plot\n",
    "num_words_to_plot = 200\n",
    "word_subset = words[:num_words_to_plot]\n",
    "word_vecs_subset = np.array([word_vectors[word] for word in word_subset])\n",
    "word_vecs_2d_subset = pca.transform(word_vecs_subset)\n",
    "cluster_labels_subset = kmeans.predict(word_vecs_subset)\n",
    "\n",
    "# Create DataFrame for Plotly\n",
    "data = {\n",
    "    'x': word_vecs_2d_subset[:, 0],\n",
    "    'y': word_vecs_2d_subset[:, 1],\n",
    "    'word': word_subset,\n",
    "    'cluster': cluster_labels_subset\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plotly scatter plot with hover text\n",
    "fig = px.scatter(df, x='x', y='y', color='cluster', hover_data={'word': True, 'x': False, 'y': False},\n",
    "                 title='Word2Vec Clusters (Subset of Words)', labels={'x': '', 'y': ''},\n",
    "                 width=800, height=600)\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
    "fig.update_layout(showlegend=True)\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-16T10:45:55.116266Z"
    }
   },
   "id": "bb623479963c361d"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Function to get average Word2Vec representation for a sentence\n",
    "def get_average_w2v(tokens):\n",
    "    vector_sum = 0\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        if word in w2v_model.wv:\n",
    "            vector_sum += w2v_model.wv[word]\n",
    "            count += 1\n",
    "    if count != 0:\n",
    "        return vector_sum / count\n",
    "    else:\n",
    "        return [0] * 100  # Return zero vector if no word found\n",
    "\n",
    "# Add Word2Vec representations to DataFrame\n",
    "X_train_w2v = [get_average_w2v(text) for text in tokenized_train_text]\n",
    "X_test_w2v = [get_average_w2v(text) for text in tokenized_test_text]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T17:06:08.277006Z",
     "start_time": "2023-11-15T17:04:40.539008Z"
    }
   },
   "id": "ca1b774973aa6131"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azagar/miniconda3/envs/is/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8535\n",
      "Random Forest Accuracy: 0.82775\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train_w2v, y_train)\n",
    "logistic_predictions = logistic_model.predict(X_test_w2v)\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "print(\"Logistic Regression Accuracy:\", logistic_accuracy)\n",
    "\n",
    "# Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train_w2v, y_train)\n",
    "rf_predictions = rf_model.predict(X_test_w2v)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T17:06:08.277448Z",
     "start_time": "2023-11-15T17:04:45.600037Z"
    }
   },
   "id": "3ee0492233050a23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using pre-trained models in NLP\n",
    "\n",
    "Pre-trained models are fundamental in the field of natural language processing (NLP) due to their ability to capture linguistic patterns and relationships from vast amounts of text data. They serve as a starting point for various NLP tasks and are incredibly useful for several reasons:\n",
    "\n",
    "1. **Generalization**: Pre-trained models are trained on large and diverse text corpora, enabling them to learn generalized representations of language. This allows them to perform reasonably well on a wide range of downstream tasks without task-specific fine-tuning.\n",
    "\n",
    "2. **Resource Efficiency**: Leveraging pre-trained models saves computational resources and time. Instead of training models from scratch, which requires substantial data and computing power, users can benefit from these pre-existing, well-trained models.\n",
    "\n",
    "3. **Transfer Learning**: Pre-trained models facilitate transfer learning, where knowledge learned from one task can be transferred to another related task. By fine-tuning or adapting pre-trained models on specific datasets or tasks, their performance can be significantly improved with minimal additional training.\n",
    "\n",
    "Fine-tuning refers to the process of taking a pre-trained model and further training it on a specific dataset or task to adapt its parameters to perform better in that particular context. Here's why fine-tuning is valuable:\n",
    "\n",
    "- **Task-specific Adaptation**: Fine-tuning allows the model to adapt to nuances and specific patterns within a target dataset or task, enhancing its performance on that particular task.\n",
    "\n",
    "- **Improved Performance**: By fine-tuning on domain-specific or task-specific data, the model can learn more task-specific features, leading to improved accuracy and effectiveness for the intended application.\n",
    "\n",
    "- **Reduced Data Requirement**: Fine-tuning often requires less data than training a model from scratch. By starting with a pre-trained model, it can efficiently learn from a smaller, domain-specific dataset, making it beneficial in scenarios where limited annotated data is available.\n",
    "\n",
    "Both pre-trained models and fine-tuning play critical roles in NLP, enabling practitioners to leverage existing knowledge and adapt it to new tasks, domains, or languages, ultimately improving the performance and efficiency of NLP applications.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "772d0044e6d28390"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: d3dcaa8d-781d-49af-88cd-2484291353e6)')' thrown while requesting HEAD https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: POSITIVE, Confidence: 0.9999\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the sentiment analysis pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Example text for sentiment analysis\n",
    "text = \"I absolutely love this product! It's fantastic!\"\n",
    "\n",
    "# Perform sentiment analysis using the pipeline\n",
    "result = sentiment_analysis(text)\n",
    "\n",
    "# Output the sentiment and confidence score\n",
    "print(f\"Sentiment: {result[0]['label']}, Confidence: {result[0]['score']:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T17:06:08.277692Z",
     "start_time": "2023-11-15T17:04:59.863546Z"
    }
   },
   "id": "fe122bc5ca65fc3d"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [02:17<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer Accuracy: 0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "trans_y_pred = []\n",
    "y_test_reset = y_test.reset_index(drop=True)\n",
    "n = 500\n",
    "\n",
    "for test_text in tqdm(X_test['text'][:n]):\n",
    "    result = sentiment_analysis(test_text[:1500])\n",
    "    sentiment = result[0]['label']\n",
    "    trans_y_pred.append('pos' if sentiment == 'POSITIVE' else 'neg')\n",
    "\n",
    "trans_accuracy = accuracy_score(y_test_reset[:n], trans_y_pred)\n",
    "print(\"Transformer Accuracy:\", trans_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T17:12:32.375177Z",
     "start_time": "2023-11-15T17:10:15.076512Z"
    }
   },
   "id": "cb84f74e7a503539"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stanza & POS tagging\n",
    "Stanza is an NLP library developed by the Stanford NLP Group. It's designed for a wide range of natural language processing tasks, including tokenization, part-of-speech tagging, named entity recognition, dependency parsing, and more. Stanza aims to provide efficient and accurate pre-trained models for various languages.\n",
    "\n",
    "Key features of Stanza include:\n",
    "- **Pre-Trained Models**: Stanza comes with pre-trained models for multiple languages, allowing users to perform various NLP tasks without training models from scratch.\n",
    "- **Ease of Use**: It offers a simple and intuitive API for performing different NLP tasks, making it accessible for both beginners and experienced researchers.\n",
    "- **Accuracy**: Stanza models are known for their high accuracy in different NLP tasks due to their robust training on extensive datasets.\n",
    "- **Multiple Languages**: Stanza supports multiple languages, making it suitable for multilingual NLP applications.\n",
    "\n",
    "Stanza provides state-of-the-art performance in various NLP tasks and continues to evolve with advancements in the field of natural language processing.\n",
    "\n",
    "### Use Case: Text Analysis with Universal POS Tagging using Stanza\n",
    "\n",
    "Stanza's Universal POS tagging can be highly beneficial in various text analysis tasks. Let's consider a scenario where you have a dataset of customer reviews for a product. By utilizing Stanza's Universal POS tagging, you can perform the following analysis:\n",
    "\n",
    "1. **Extracting Key Features**: Identify the key features or attributes of the product mentioned in the reviews by analyzing nouns (NOUN) and adjectives (ADJ) tagged using Stanza. This helps in understanding what aspects of the product are being praised or criticized.\n",
    "\n",
    "2. **Sentiment Analysis**: Analyze sentiments associated with specific parts of speech. For instance, adjectives (ADJ) often reflect sentiments or opinions. By associating adjectives with their corresponding nouns, you can determine the sentiment expressed towards various product features.\n",
    "\n",
    "3. **Customer Feedback Categorization**: Categorize customer feedback into different categories based on the identified parts of speech. For instance, categorize reviews mentioning \"customer service\" (PROPN) separately to analyze the sentiment specifically related to that aspect.\n",
    "\n",
    "4. **Comparative Analysis**: Compare the frequency and sentiment of different parts of speech across different products or time frames to identify trends and patterns in customer opinions.\n",
    "\n",
    "By utilizing Stanza's Universal POS tagging, you can effectively extract meaningful insights from textual data, enabling better decision-making and improving products or services based on customer feedback.\n",
    "\n",
    "### Universal POS Tags\n",
    "- **ADJ**: Adjective\n",
    "- **ADP**: Adposition\n",
    "- **ADV**: Adverb\n",
    "- **AUX**: Auxiliary\n",
    "- **CCONJ**: Coordinating conjunction\n",
    "- **DET**: Determiner\n",
    "- **INTJ**: Interjection\n",
    "- **NOUN**: Noun\n",
    "- **NUM**: Numeral\n",
    "- **PART**: Particle\n",
    "- **PRON**: Pronoun\n",
    "- **PROPN**: Proper noun\n",
    "- **PUNCT**: Punctuation\n",
    "- **SCONJ**: Subordinating conjunction\n",
    "- **SYM**: Symbol\n",
    "- **VERB**: Verb\n",
    "- **X**: Other"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c76a4bc0d8cd9989"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json: 367kB [00:00, 2.39MB/s]                    \n",
      "2023-11-16 11:04:08 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-11-16 11:04:10 INFO: File exists: /Users/azagar/stanza_resources/en/default.zip\n",
      "2023-11-16 11:04:14 INFO: Finished downloading models and saved to /Users/azagar/stanza_resources.\n",
      "2023-11-16 11:04:14 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json: 367kB [00:00, 2.39MB/s]                    \n",
      "2023-11-16 11:04:15 INFO: Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2023-11-16 11:04:15 INFO: Using device: cpu\n",
      "2023-11-16 11:04:15 INFO: Loading: tokenize\n",
      "2023-11-16 11:04:15 INFO: Loading: pos\n",
      "2023-11-16 11:04:15 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Nouns: ['camera', 'quality', 'battery', 'life']\n",
      "Extracted Adjectives: ['amazing', 'better']\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "# Download English model (change 'en' to the appropriate language code if needed)\n",
    "stanza.download('en')\n",
    "\n",
    "# Initialize the English pipeline\n",
    "nlp = stanza.Pipeline('en', processors='tokenize,pos')\n",
    "\n",
    "# Sample customer review\n",
    "sample_review = \"The camera quality is amazing, but the battery life could be better.\"\n",
    "\n",
    "# Process the review\n",
    "doc = nlp(sample_review)\n",
    "\n",
    "# Extract nouns and adjectives\n",
    "nouns = []\n",
    "adjectives = []\n",
    "\n",
    "for sentence in doc.sentences:\n",
    "    for word in sentence.words:\n",
    "        if word.upos == 'NOUN':\n",
    "            nouns.append(word.text)\n",
    "        elif word.upos == 'ADJ':\n",
    "            adjectives.append(word.text)\n",
    "\n",
    "# Print extracted nouns and adjectives\n",
    "print(\"Extracted Nouns:\", nouns)\n",
    "print(\"Extracted Adjectives:\", adjectives)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T10:04:16.150895Z",
     "start_time": "2023-11-16T10:04:07.452456Z"
    }
   },
   "id": "4d729e48866f6451"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
